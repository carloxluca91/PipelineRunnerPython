[configuration]

# Spark
spark.savemode.append = append
spark.savemode.overwrite = overwrite

########################################################################################################################
# Csv
csv.dir.path = C:\\Users\\carlo\\Cloudera\\Data\\PipelineRunnerPython\\CSV

########################################################################################################################
# Json
pipeline.json.dir.path = C:\\Users\\carlo\\Cloudera\\Data\\PipelineRunnerPython\\Pipeline

########################################################################################################################
# JDBC
jdbc.default.host = 127.0.0.1
jdbc.default.port = 3306
jdbc.default.url = jdbc:mysql://${jdbc.default.host}:${jdbc.default.port}
jdbc.default.driver.className = com.mysql.jdbc.Driver
jdbc.default.userName = luca
jdbc.default.passWord = Velvet2791!
jdbc.default.useSSL = False
jdbc.default.createDbIfNotExists = True

jdbc.db.pypelineRunner.name = pypeline_runner
jdbc.db.lakeCedacri.name = lake_cedacri

jdbc.table.logTable.name = log_table
jdbc.table.pipelineInfo.name = pypeline_info

########################################################################################################################
# Hive
hive.default.createDatabaseIfNotExists = ${jdbc.default.createDbIfNotExists}

hive.db.pypelineRunner.name = ${jdbc.db.pypelineRunner.name}
hive.db.lakeCedacri.name = ${jdbc.db.lakeCedacri.name}

hive.table.pipelineInfo.name = ${jdbc.table.pipelineInfo.name}

########################################################################################################################
# Initial Load
initialLoad.json.file.path = ${pipeline.json.dir.path}\\initial_load.json

csv.initialLoad.csv.path = ${csv.dir.path}\\pipeline_info_data.tsv
csv.initialLoad.schema.path = ${csv.dir.path}\\pipeline_info_schema.json
csv.initialLoad.separator = \t

jdbc.initialLoad.dbName = ${jdbc.db.pypelineRunner.name}
jdbc.initialLoad.tableName = ${jdbc.table.pipelineInfo.name}

hive.initialLoad.dbName = ${hive.db.pypelineRunner.name}
hive.initialLoad.tableName = ${jdbc.table.pipelineInfo.name}

########################################################################################################################
# Load Int006
jdbc.loadInt006.actual.name = t_rd_int006
jdbc.loadInt006.historical.name = ${jdbc.loadInt006.actual.name}_h
