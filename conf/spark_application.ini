[hdfs]

pipeline.json.dir.path = C:\\Users\\carlo\\Cloudera\\Data\\PipelineRunnerPython\\Pipeline
pipeline.initialLoad.json.fileName = initial_load.json
pipeline.initialLoad.json.file.path = ${pipeline.json.dir.path}\\${pipeline.initialLoad.json.fileName}

[jdbc]

jdbc.default.host = 127.0.0.1
jdbc.default.port = 3306
jdbc.default.url = jdbc:mysql://${jdbc.default.host}:${jdbc.default.port}
jdbc.default.driver.className = com.mysql.jdbc.Driver
jdbc.default.userName = luca
jdbc.default.passWord = Velvet2791!
jdbc.default.useSSL = False

jdbc.default.dbName = pypeline_runner
jdbc.default.createDbIfNotExists = True

jdbc.default.logTable = log_table
jdbc.default.logTable.full = ${jdbc.default.dbName}.${jdbc.default.logTable}
jdbc.default.logTable.saveMode = append

jdbc.default.pipelineInfoTable = pypeline_info
jdbc.default.pipelineInfoTable.full = ${jdbc.default.dbName}.${jdbc.default.pipelineInfoTable}
jdbc.default.pipelineInfoTable.saveMode = overwrite

pipeline.initialLoad.dst.jdbc.df1.saveMode = overwrite
pipeline.initialLoad.dst.jdbc.df1.dbName = ${jdbc.default.dbName}
pipeline.initialLoad.dst.jdbc.df1.tableName = ${jdbc.default.pipelineInfoTable}
pipeline.initialLoad.dst.jdbc.df1.createDatabaseIfNotExists = ${jdbc.default.createDbIfNotExists}

[hive]

hive.default.dbName = ${jdbc:jdbc.default.dbName}
hive.default.createDatabaseIfNotExists = ${jdbc:jdbc.default.createDbIfNotExists}

hive.default.pipelineInfoTable = ${jdbc:jdbc.default.pipelineInfoTable}
hive.default.pipelineInfoTable.full = ${jdbc.default.dbName}.${jdbc.default.pipelineInfoTable}
hive.default.pipelineInfoTable.saveMode = overwrite

pipeline.initialLoad.dst.hive.df1.saveMode = overwrite
pipeline.initialLoad.dst.hive.df1.dbName = ${hive.default.dbName}
pipeline.initialLoad.dst.hive.df1.tableName = ${jdbc:pipeline.initialLoad.dst.jdbc.df1.tableName}
pipeline.initialLoad.dst.hive.df1.createDatabaseIfNotExists = True

[csv]

csv.default.dir.path = C:\\Users\\carlo\\Cloudera\\Data\\PipelineRunnerPython\\CSV

pipeline.initialLoad.src.csv.df1.path = ${csv.default.dir.path}\\pipeline_info_data.tsv
pipeline.initialLoad.src.csv.df1.schema = ${csv.default.dir.path}\\pipeline_info_schema.json
pipeline.initialLoad.src.csv.df1.separator = \t